{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9d70efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Additional Libraries\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05b4a07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "047e0a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "X = df.drop('Default', axis=1)  # Features\n",
    "y = df['Default']                # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f446bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the folder path\n",
    "interim_folder = r\"C:\\Users\\DELL\\Desktop\\FDM Mini Project\\Automobile Loan Default Prediction\\weighted method\\data\\interim\"\n",
    "\n",
    "# Make sure the folder exists\n",
    "os.makedirs(interim_folder, exist_ok=True)\n",
    "\n",
    "# Combine X_train and y_train into a single DataFrame\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# Combine X_test and y_test into a single DataFrame\n",
    "test_df = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "# Save as CSV\n",
    "train_df.to_csv(os.path.join(interim_folder, \"train.csv\"), index=False)\n",
    "test_df.to_csv(os.path.join(interim_folder, \"test.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8c864e",
   "metadata": {},
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acc05fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "Training Accuracy: 0.9999100948499333\n",
      "Testing Accuracy: 0.9115972430326641\n",
      "Confusion Matrix:\n",
      " [[15194     6]\n",
      " [ 1469    16]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     15200\n",
      "           1       0.73      0.01      0.02      1485\n",
      "\n",
      "    accuracy                           0.91     16685\n",
      "   macro avg       0.82      0.51      0.49     16685\n",
      "weighted avg       0.90      0.91      0.87     16685\n",
      "\n",
      "\n",
      "  Model saved as 'rf_model_weighted.pkl'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Define the model with class weighting\n",
    "rf_model = RandomForestClassifier(class_weight={0: 1, 1: 10})\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = accuracy_score(y_train, rf_model.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, rf_model.predict(X_test))\n",
    "\n",
    "print(\"Random Forest Classifier:\")\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "\n",
    "#  6. Save the trained model\n",
    "joblib.dump(rf_model, 'C:/Users/DELL/Desktop/FDM Mini Project/Automobile Loan Default Prediction/weighted method/models/rf_model_weighted.pkl')\n",
    "print(\"\\n  Model saved as 'rf_model_weighted.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10d15db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters (Random Forest): {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Random Forest Classifier:\n",
      "Training Accuracy: 0.9998801264665778\n",
      "Testing Accuracy: 0.9115972430326641\n",
      "Confusion Matrix:\n",
      " [[15194     6]\n",
      " [ 1469    16]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     15200\n",
      "           1       0.73      0.01      0.02      1485\n",
      "\n",
      "    accuracy                           0.91     16685\n",
      "   macro avg       0.82      0.51      0.49     16685\n",
      "weighted avg       0.90      0.91      0.87     16685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Define the model\n",
    "rf_model_hyper = RandomForestClassifier()\n",
    "\n",
    "# Define hyperparameters for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_depth': [None, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search_rf = GridSearchCV(rf_model_hyper, param_grid, cv=5)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "best_hyperparameters = grid_search_rf.best_params_\n",
    "print(\"Best Hyperparameters (Random Forest):\", best_hyperparameters)\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = accuracy_score(y_train, grid_search_rf.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, grid_search_rf.predict(X_test))\n",
    "\n",
    "print(\"Random Forest Classifier:\")\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "\n",
    "# Make predictions on the test set using the best model found by GridSearchCV\n",
    "y_pred = grid_search_rf.predict(X_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4c4dc7",
   "metadata": {},
   "source": [
    "Support Vector Classification (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb906d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier:\n",
      "Training Accuracy: 0.600776181128909\n",
      "Testing Accuracy: 0.5922685046448907\n",
      "Confusion Matrix:\n",
      " [[8983 6217]\n",
      " [ 586  899]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.59      0.73     15200\n",
      "           1       0.13      0.61      0.21      1485\n",
      "\n",
      "    accuracy                           0.59     16685\n",
      "   macro avg       0.53      0.60      0.47     16685\n",
      "weighted avg       0.87      0.59      0.68     16685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the model with class weighting\n",
    "svm_model = SVC(class_weight={0: 1, 1: 10})\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = accuracy_score(y_train, svm_model.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, svm_model.predict(X_test))\n",
    "\n",
    "print(\"SVM Classifier:\")\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53de3d8",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f7cc01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier:\n",
      "Training Accuracy: 0.10815589553021562\n",
      "Testing Accuracy: 0.10740185795624813\n",
      "Confusion Matrix:\n",
      " [[  327 14873]\n",
      " [   20  1465]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.02      0.04     15200\n",
      "           1       0.09      0.99      0.16      1485\n",
      "\n",
      "    accuracy                           0.11     16685\n",
      "   macro avg       0.52      0.50      0.10     16685\n",
      "weighted avg       0.87      0.11      0.05     16685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the model (note: class_weight has no effect in GaussianNB)\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# Fit the model\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = accuracy_score(y_train, nb_model.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, nb_model.predict(X_test))\n",
    "\n",
    "print(\"Naive Bayes Classifier:\")\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = nb_model.predict(X_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b94b5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier:\n",
      "Training Accuracy: 0.10815589553021562\n",
      "Testing Accuracy: 0.10740185795624813\n",
      "Confusion Matrix:\n",
      " [[  327 14873]\n",
      " [   20  1465]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.02      0.04     15200\n",
      "           1       0.09      0.99      0.16      1485\n",
      "\n",
      "    accuracy                           0.11     16685\n",
      "   macro avg       0.52      0.50      0.10     16685\n",
      "weighted avg       0.87      0.11      0.05     16685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Define the model\n",
    "nb_model_hyper = GaussianNB()\n",
    "\n",
    "# No hyperparameters to tune for Gaussian Naive Bayes\n",
    "\n",
    "# Fit the model\n",
    "nb_model_hyper.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = accuracy_score(y_train, nb_model_hyper.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, nb_model_hyper.predict(X_test))\n",
    "\n",
    "print(\"Naive Bayes Classifier:\")\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = nb_model_hyper.predict(X_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500561a6",
   "metadata": {},
   "source": [
    "Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb0becb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.6361988102551808\n",
      "Testing Accuracy: 0.6255918489661373\n",
      "Confusion Matrix:\n",
      " [[9552 5648]\n",
      " [ 599  886]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.63      0.75     15200\n",
      "           1       0.14      0.60      0.22      1485\n",
      "\n",
      "    accuracy                           0.63     16685\n",
      "   macro avg       0.54      0.61      0.49     16685\n",
      "weighted avg       0.87      0.63      0.71     16685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Compute weights for each sample\n",
    "weights = compute_sample_weight(class_weight={0: 1, 1: 10}, y=y_train)\n",
    "\n",
    "# Create model\n",
    "gb_model = GradientBoostingClassifier()\n",
    "\n",
    "# Fit with weights\n",
    "gb_model.fit(X_train, y_train, sample_weight=weights)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = gb_model.predict(X_test)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, gb_model.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9a5583f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters (GradientBoostingClassifier): {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 100}\n",
      "Gradient Boosting Classifier:\n",
      "Training Accuracy: 0.9110238698173427\n",
      "Testing Accuracy: 0.9109979023074618\n",
      "Confusion Matrix:\n",
      " [[15200     0]\n",
      " [ 1485     0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     15200\n",
      "           1       0.00      0.00      0.00      1485\n",
      "\n",
      "    accuracy                           0.91     16685\n",
      "   macro avg       0.46      0.50      0.48     16685\n",
      "weighted avg       0.83      0.91      0.87     16685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Define the model\n",
    "gb_model_hyper = GradientBoostingClassifier()\n",
    "\n",
    "# Define hyperparameters for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search_gb = GridSearchCV(gb_model_hyper, param_grid, cv=5)\n",
    "grid_search_gb.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "best_hyperparameters = grid_search_gb.best_params_\n",
    "print(\"Best Hyperparameters (GradientBoostingClassifier):\", best_hyperparameters)\n",
    "\n",
    "# Evaluate the model using GridSearchCV results\n",
    "train_accuracy = accuracy_score(y_train, grid_search_gb.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, grid_search_gb.predict(X_test))\n",
    "\n",
    "print(\"Gradient Boosting Classifier:\")\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "\n",
    "# Make predictions on the test set using the best model found by GridSearchCV\n",
    "y_pred = grid_search_gb.predict(X_test)\n",
    "\n",
    "# Compute the confusion matrix and classification report\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53ecd5c",
   "metadata": {},
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e259e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier:\n",
      "Training Accuracy: 0.9999700316166444\n",
      "Testing Accuracy: 0.8445909499550495\n",
      "Confusion Matrix:\n",
      " [[13882  1318]\n",
      " [ 1275   210]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91     15200\n",
      "           1       0.14      0.14      0.14      1485\n",
      "\n",
      "    accuracy                           0.84     16685\n",
      "   macro avg       0.53      0.53      0.53     16685\n",
      "weighted avg       0.85      0.84      0.85     16685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the model with class weighting\n",
    "dt_model = DecisionTreeClassifier(class_weight={0: 1, 1: 10})\n",
    "\n",
    "# Fit the model\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = accuracy_score(y_train, dt_model.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, dt_model.predict(X_test))\n",
    "\n",
    "print(\"Decision Tree Classifier:\")\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = dt_model.predict(X_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9619649d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters (Decision Tree): {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
      "Decision Tree Classifier:\n",
      "Training Accuracy: 0.9118779687429761\n",
      "Testing Accuracy: 0.9095594845669763\n",
      "Confusion Matrix:\n",
      " [[15170    30]\n",
      " [ 1479     6]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     15200\n",
      "           1       0.17      0.00      0.01      1485\n",
      "\n",
      "    accuracy                           0.91     16685\n",
      "   macro avg       0.54      0.50      0.48     16685\n",
      "weighted avg       0.84      0.91      0.87     16685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Define the model\n",
    "dt_model_hyper = DecisionTreeClassifier()\n",
    "\n",
    "# Define hyperparameters for tuning\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search_dc = GridSearchCV(dt_model_hyper, param_grid, cv=5)\n",
    "grid_search_dc.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "best_hyperparameters = grid_search_dc.best_params_\n",
    "print(\"Best Hyperparameters (Decision Tree):\", best_hyperparameters)\n",
    "\n",
    "# Get the best model\n",
    "best_dt_model = grid_search_dc.best_estimator_\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = accuracy_score(y_train, best_dt_model.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, best_dt_model.predict(X_test))\n",
    "\n",
    "print(\"Decision Tree Classifier:\")\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_dt_model.predict(X_test)\n",
    "\n",
    "# Compute the confusion matrix and classification report\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loan_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
